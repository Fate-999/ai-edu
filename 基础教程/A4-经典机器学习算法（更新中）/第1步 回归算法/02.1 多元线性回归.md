## 2.1 多元线性回归

### 多元线性回归的简单例子

第一章中学习了在二维平面上，解决线性回归问题的最小二乘法，那么这个方法是否可以扩展到三维空间上呢？我们来举一个具体的例子。

房价预测问题，成为了机器学习的一个入门话题，著名的波士顿的房价数据及相关的比赛已经很多了，但是美国的房子都是独栋的，前院后院停车库游泳池等等参数非常多，初学者可能理解起来有困难。我们不妨用简化版的北京通州的房价来举例，感受一下房价预测的过程。

影响北京通州房价的因素有很多，居住面积、地理位置、朝向、学区房、周边设施、建筑年份等等，其中，面积和地理位置是两个比较重要的因素。地理位置信息一般采用经纬度方式表示，但是经纬度是两个特征值，联合起来才有意义，因此，我们把它转换成了到通州区中心的距离。

<img src="./images/2-1-1.png" />
<center>图 2.1.1 房价与地理位置及面积的关系</center>

在图 2.1.1 中，房屋面积（大小）近似用方形 S 来表示，位置用 R 来表示。

所以，房屋价格应该是 $S、R$ 的函数，即 $Price = f(S,R)$。在这个问题中，我们假设函数 $f$ 是一个线性函数，即：

$$
y = a_1x_1 + a_2x_2 + b + \varepsilon \tag{2.1.1}
$$

- $x_1$ 是房屋距离市中心的距离 R，取值范围为 $2 \sim 20$ 公里，越靠近市中心的房价越高，所以 $x_1$ 是个反向指标。
- $x_2$ 是房屋的面积 S，取值范围为 $40 \sim 120$ 平方米，面积越大房价越高，所以 $x_2$ 是个正向指标。
- $y$ 标签值是房屋价格，单位万元。
- $\varepsilon$ 是一个噪音，$\varepsilon \sim N(0, \sigma^2)$

正向/反向指标的含义是：该特征值 $x$ 越大，标签值 $y$ 也越大，即正相关关系；否则就是反向指标。

### 制作数据集

参数假设：

- $a_1 = 2$，表示每距离市中心近 1 公里，总价就会多 2 万。
- $a_2 = 4$，表示每平米均价 4 万元。
- $b = 10$，表示房屋基本价是 10 万起。

$$
y = 2(20-x_1) + 4 x_2 + 10
$$


我们有 500 个样本，每个样本有两个特征值，一个标签值，示例如表 2.1.1。

表 2.1.1 房价问题样本示例

|样本序号|距离 x1|面积 x2|房价 y|
|--|--|--|--|
|1|20.922014 | 98.860146 | 452.128786|
|2|11.742079 | 83.686204 | 373.487686|
|3|14.574086 | 80.328539 | 365.477199|
|4|6.653045 | 65.807237 | 291.611815|
|5|8.890379 | 81.919936 | 360.511960|
|...|...... |......|......|
